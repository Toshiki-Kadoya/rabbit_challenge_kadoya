機械学習

【自己学習】
①線形回帰モデル
・Vapnikの原理→「ある問題を解くとき、その問題よりも難しい問題を途中段階で解いてはならない。」
　↑プログラマの教訓的によく使われる。
・密度比推定・・・実際のアルゴリズムではデータの分布を推定するのではなく、密度比を直接推定する。
・外れ値に頑健な損失(誤差)の表し方
　→例:)絶対値損失、Huber損失、Tukey損失  ※二乗誤差だと外れ値が余計に大きく外れるため。
・射影行列→あるベクトルに作用させると、そのベクトルの部分空間成分を取り出すような行列
・外挿問題→外挿とは、モデルを作る時に使ったデータの範囲外についての予測。
　　　　　　予測の目的やモデルによっては、外挿をしてはいけないことがある。
　　　　　　　→決定木関連のモデルでは要注意。


②非線形回帰モデル
・基底関数とは
　　→求めたい解をあらかじめ用意した何個かの関数群の線形結合で表すときに用いられる関数のこと。
　　　文字通り，関数を表現するベースとして使うもの。
・ガウス型基底関数
　　→ガウス基底はデータ点の情報を近い距離に効率的に反映させることのできる基底。
　　　ガウス関数(平均、標準偏差)で表現。
・正則化
　　→回帰式が複雑な形状になった場合にペナルティを設けることで、回帰式をなるべくシンプルな形状に保つテクニック。
　　・L2正則化を使用すると、パラメータの大きさが抑制される。
　　・L1正則化を使用すると、いくつかのパラメータを 0 にすることができる。→特徴選択を行っている。


③ロジスティック回帰モデル
・Using ML to Predict Parking Difficulty[参照:Google AI Blog:2017 Feb]　→特定の問題を考えるときにdeep learningを用いるより、ロジステック回帰を用いた方が精度が良い場合もある。
・識別的アプローチ: -->識別関数の構成もある。{F(x)>0 ⇒ C=1,F(x)<0 ⇒ C=0}
　　→P(c|x)を直接モデル化
・生成的アプローチ:
　　→P(c)とP(x|c)をモデル化し、その後、ベイズの定理を用いてP(c|x)を求める
　　　P(c|x) = P(c∧x)/P(x) = P(x|c)・P(c)/P(x)


④主成分分析
・主成分分析(PCA)はデータセットの特徴量を相互に統計的に関連しないように回転させる手法。多くの場合回転した後の特徴量から、データの説明に重要な一部の特徴量だけを抜き出す。
　→最も分散が大きい方向を「第一成分」、第一成分に直交し、最も情報を持っている成分を「第二成分」とする。
・可視化、データの圧縮、表現の発見が主な用途。
・主成分分析の流れ
　　1.分析の目的を定め，データを用意する
　　2.固有ベクトル，寄与率，主成分を求める
　　3.結果から主成分の解釈を行う


⑤アルゴリズム
・決定木
　　→決定木における学習は，正解に最も早くたどり着けるような一連のYES/NO型の質問の学習を意味する。
　・結果のモデルが容易に可視化可能。(人が解釈しやすい形で出力)
　・個々の特徴量は独立に処理され、データの分割はスケールに依存しないので、決定木においては特徴量の正規化や標準化が必要ない
　・二値特徴量と連続値特徴量が混ざっていても問題ない
　　→前処理がラク。

・ランダムフォレスト
　　→少しづつ異なる決定木を沢山集めたもの。ランダムフォレストは、個々の決定木は比較的うまく予測出来ているが、一部のデータに対して過剰適合してしまっているという考えに基づいている。
　　それぞれ異なった方向に過剰適合した決定木を沢山作れば、その結果の平均を取ることで過剰適合の度合いを減らすことが出来る。

・勾配ブースティング決定木
　　→一つ前の決定木の誤りを次の決定木が修正するようにして、決定木を順番に作っていく。勾配ブースティングのポイントは浅い決定木のような、簡単なモデルを多数組み合わせることにある。
　・ランダムフォレストに比べ、パラメータ設定の影響を受けやすいが正しく設定されていれば、こちらの方が性能が良く出る。


⑥サポートベクターマシーン
　　→線形、非線形のどちらも扱うことが可能。
　　　以下、主なメリット・デメリットを記載。
　　　・メリット:1.データの次元が大きくなっても識別精度が良い。
 　　　　　　　　2.最適化すべきパラメータが少ない。　→チューニングがラク。
　　　・デメリット:1.学習データが増えると計算量が膨大になる。
　　　　　　　　　 2.基本的に２クラス分類に特化している。　→決定境界により分類するため。
　　　　　　　　 　3.スケーリングが必要。　→正規化など。



----------------------------------------
[メモ]学習のキーワード、参考文献
　キーワード
　　・半教師あり学習

　参考文献
　　・機械学習のエッセンス
　　・Pythonではじめる機械学習 scikit-learnで学ぶ特徴量エンジニアリングと機械学習の基礎
　　・Pythonで動かして学ぶ！ あたらしい機械学習の教科書



