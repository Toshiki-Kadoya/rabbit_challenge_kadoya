深層学習_後編_day4

【要点のまとめ】

①Section1:強化学習
・強化学習とは、長期的に報酬を最大化できるように環境のなかで行動を選択できるエージェントを作ることを目標とする機械学習の一分野。
　→行動の結果として与えられる利益(報酬)をもとに、行動を決定する原理を改善していく仕組み。
　→強化学習では、優れた方策を見つけることが目標。
・エージェントが方策:Πの行動をとり、環境の状態:Sを変える。状態変化に応じた報酬(価値:V)を受け取る。
・探索と利用
　探索:不完全な知識を元に行動しながら、データを収集。最適な行動を見つけていく。
　利用:過去の経験(データ)を活かして行動。
　→トレードオフの関係
　　・過去のデータで、ベストとされる行動のみを常に取り続ければ他にもっとベストな行動を見つけることはできない。
　　　→探索が足りない状態
　　・利用が足りない状況
　　　→未知の行動のみを常に取り続ければ、過去の経験が活かせない。
・方策→方策関数:Π(s,a)、価値→行動価値関数:Q(s,a)
・Q学習→　行動価値関数を、行動する毎に更新することにより学習を進める方法。
・関数近似法→価値関数や方策関数を関数近似する手法のこと。
・価値関数とは　→価値を表す関数としては、状態価値関数と行動価値関数の2種類がある。
　　　　　　　　→ある状態の価値に注目する場合は、状態価値関数。
　　　　　　　　→状態と価値を組み合わせた価値に注目する場合は、行動価値関数。
・方策関数とは　→方策ベースの強化学習手法において、ある状態でどのような行動を採るのかの確率を与える関数のこと。
・方策関数を学習させる方法　→方策勾配法:θ = θ + ε▽J(θ)
　　　　　　　　　　　　　　→報酬を最大化させる≒J(期待収益)を増やす


②Section2:AlphaGo
・AlphaGo Lee→PolocyNet:方策関数、ValueNet：価値関数
　　　　　　　 →入力画像が盤面のため、畳み込みニューラルネットワークでできている。また、入力は48チャンネルある。
・AlphaGoの学習ステップ
　→1.教師あり学習によるRollOutPolicyとPolicyNetの学習
　　2.強化学習によるPolicyNetの学習
　　3.強化学習によるValueNetの学習
・RollOutPolicy→NNではなく線形の方策関数。探索中に高速に着手確率を出すために使用される。
・AlphaGo Zero→AlphaGo Leeとの違い
　　　　　　　　　・教師あり学習を一切行わず、強化学習のみで作成。
　　　　　　　　　・特徴入力からヒューリスティックな要素を排除し、石の配置のみにした。
　　　　　　　　　・PolicyNetとValueNetを１つのネットワークに統合した。
　　　　　　　　　・Residual Netを導入した。
　　　　　　　　　・モンテカルロ木探索からRollOutシミュレーションをなくした。
・Residual Net→ネットワークにショートカット構造を追加して、勾配の爆発、消失を抑える効果を狙ったもの。
　　　　　　　　Residula Networkを使うことにより、100層を超えるネットワークでの安定した学習が可能となった。
　　　　　　　　また、Resisual Networkを使うことにより層数の違うNetworkのアンサンブル効果が得られているという説もある。


③Section3:軽量化・高速化技術
・分散深層学習→複数の計算資源(ワーカー)を使用し、並列的にニューラルネットを構成することで、効率の良い学習を行いたい。
　　　　　　　　データ並列化、モデル並列化、GPUによる高速技術は不可欠。
・データ並列化→親モデルを各ワーカーに子モデルとしてコピー。
　　　　　　　　データを分割し、各ワーカーごとに計算させる。
・データ並列化は各モデルのパラメータの合わせ方で、同期型か非同期型か決まる。
　　・同期型:各ワーカーが計算が終わるのを待ち、全ワーカーの勾配が出たところで勾配の平均を計算し、親モデルのパラメータを更新する。
　　・非同期型:各ワーカーはお互いの計算を待たず、各子モデルごとに更新を行う。学習が終わった子モデルはパラメータサーバにPushされる。
　　　新たに学習を始める時は、パラメータサーバからPopしたモデルに対して学習していく。
　→両者の比較
　　・処理のスピードは、お互いのワーカーの計算を待たない非同期型の方が早い。
　　・非同期型は最新のモデルのパラメータを利用できないので、学習が不安定になりやすい。
　　・現在は同期型の方が精度が良いことが多いので、主流となっている。
・モデル並列化→親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。
　　　　　　　　全てのデータで学習が終わった後で、一つのモデルに復元。
・モデルが大きい時はモデル並列化を、データが大きい時はデータ並列化をすると良い。
・GPUによる高速化→GPUは簡単な並列処理が得意。ニューラルネットの学習は単純な行列演算が多いので、高速化が可能。
・軽量化の方法→量子化、蒸留、プルーニング
・量子化→通常のパラメータの64bit浮動小数点を32bitなど下位の精度に落とすことでメモリと演算処理の削減を行う。
・量子化の利点と欠点
　　利点:計算の高速化、省メモリ化
　　欠点:精度の低下
・蒸留→規模の大きなモデルの知識を使い軽量なモデルの作成を行う。
　　　　モデルの簡約化:学習済みの精度の高いモデルの知識を軽量なモデルへ継承させる。
・プルーニング→モデルの精度に寄与が少ないニューロンを削減することでモデルを圧縮し、高速に計算を行うことができる。
　　　　　　　→ニューロンの削減:ニューロンの削減の手法は重みが閾値以下の場合ニューロンを削減し、再学習を行う。


④Section4:応用モデル
・MobileNet→画像認識のディープラーニングモデルの軽量化・高速化・高精度化を実現。
　　　　　　 一般的な畳み込み層は計算量が多いため、Depthwise Convolution(フィルタ数:M=1)とPointwise Convolution(フィルタの縦横数:K=1)の組み合わせで軽量化を実現。
　　　　　　　→Depthwise Separable Convolutionという手法を用いて計算量を削減している。

・DenseNet→畳み込みニューラルネットワークのアーキテクチャの一種。
　　　　　　DenseBlockと呼ばれるモジュールを使用。
　　　　　　　→出力層に前の層の入力を足しあわせる。(層間の情報の伝達を最大にするために全ての同特徴量サイズの層を結合する。)
　　　　　→Transition Layer(特徴マップのサイズを変更し、ダウンサンプリングを行う)と呼ばれる層でDence blockをつなぐ。
　　　・DenseNet内で使用されるDenseBlockと呼ばれるモジュールでは成⻑率(Growth Rate)と呼ばれるハイパーパラメータが存在する。
　　　　→DenseBlock内の各ブロック毎にk個ずつ特徴マップのチャネル数が増加していく時、kを成長率と呼ぶ。

・Batch Norm、Layer Norm、Instance Norm　→学習時間の短縮や初期値への依存低減、過学習の抑制など効果がある。
　　・Batch Norm→ミニバッチに含まれるsampleの同一チャネルが同一分布に従うよう正規化。
　　　　　　　　　Batch Sizeが小さい条件下では、学習が収束しないことがあり、代わりにLayer Normalizationなどの正規化手法が使われることが多い。
　　・Layer Norm→それぞれのsampleの全てのpixelsが同一分布に従うよう正規化。（一枚の画像に対して正規化）
　　・Instance Norm→さらにchannelも同一分布に従うよう正規化。（一枚の画像の一つのチャンネルに対して正規化）

・Wavenet→生の音声波形を生成する深層学習モデル。CNNを音声に応用。
　　　　　 Dilated causal convolution(層が深くなるにつれて畳み込みリンクを離す)を使用。
　　　　　 受容野を簡単に増やすことができるという利点がある。


⑤Section5:Transformer
・Seq2seq→系列(Sequence)を入力として、系列を出力するもの。Encoder-Decoderモデルとも呼ばれる。
　　　　　 入力系列がEncode(内部状態に変換)され、内部状態からDecode(系列に変換)する。
・言語モデルとは、言語モデルは単語の並びに確率を与える。
　→単語の並びに対して尤度(それがどれだけ起こり得るか)、すなわち、文章として自然かを確率で評価する。
　→時刻t-1までの情報で、時刻tの事後確率を求めることが目標。
・Decoderのoutput側に正解を当てれば教師あり学習がEnd2endで行える。
・Transformer→RNNを使わず、Attention(注意機構)のみを用いて作られたSeq2seqモデル。
・注意機構には2種類ある。→ソース・ターゲット注意機構、自己注意機構


⑥Section6:物体検知・セグメンテーション
・物体検知→出力:Bounding Box(物体の位置)+クラスラベル
・Semantic Segmentation(意味領域分割)→出力:各ピクセルに対し単一のクラスラベル
・Instance Segmentation(個体領域分割)→出力:各ピクセルに対し単一のクラスラベル
・代表的なデータセット:VOC12、ILSVRC17、MS COCO18、OICOD18
　→クラス数、サンプル数(Train+Val)、Box/画像(一枚あたりに写っている物体の数)にそれぞれ違いがある。
　→目的に応じたデータセットを使うべき。
・物体検出においてはクラスラベルだけでなく, 物体位置の予測精度も評価。
　→物体位置の精度評価の指標　IoU:Intersection over Union
・応用上の要請から、検出精度に加え検出速度も問題となる。
・物体検知のフレームワーク
　　・２段階検出器（Two-stage detector）
　　　　→・候補領域の検出とクラス推定を別々に行う
　　　　　・相対的に精度が高い傾向
　　　　　・相対的に計算量が大きく推論も遅い傾向
　　・１段階検出器（One-stage detector）
　　　　→・候補領域の検出とクラス推定を同時に行う
　　　　　・相対的に精度が低い傾向
　　　　　・相対的に計算量が小さく推論も早い傾向
・SSD(Single Shot Detector)→1.Default BOXを用意。
　　　　　　　　　　　　　　 2.Default BOXを変形し、conf.を出力。
・Semantic Segmentation(意味領域分割)→落ちた解像度をもとの解像度に戻す:Up-sampling
　　　　　　　　　　　　　　　　　　　　　→Deconvolution/Transposed convolution


⑦その他:DCGAN
・GAN(Generative Adversarial Nets)とは、生成器と識別器を競わせて学習する生成＆識別モデル。
　　・Generator:乱数からデータを生成。
　　・Discriminator:入力データが真データ(学習データ)であるかを識別。
・DCGAN(Deep Convolutional GAN)とは、GANを利用した画像生成モデル。いくつかの構造制約により生成品質を向上。


